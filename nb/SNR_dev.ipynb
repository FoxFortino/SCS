{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "defb54d1-95e2-4880-b9f1-ce613b1bc2bb",
   "metadata": {},
   "source": [
    "Advice from fed\n",
    "\n",
    "In linear space, noise is a multiplicative factor. So I need to figure out a noise profile from each spectrum and scale it. Smooth the original spectrum, take the difference between the smoothed and the original spectrum, and then those residuals will be the noise profile (until we can talk to marc and get that code to extract noise profile more cleverly).\n",
    "\n",
    "Can also do this additively in log space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "459963d8-df16-431c-b744-7f975c8c82f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from os.path import isfile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow_addons.metrics import F1Score\n",
    "\n",
    "# My packages\n",
    "sys.path.insert(0, \"/Users/admin/Code/SCS/scs/\")\n",
    "import data_degrading as dd\n",
    "import data_preparation as dp\n",
    "import data_augmentation as da\n",
    "from prepare_datasets_for_training import extract\n",
    "import data_plotting as dplt\n",
    "import scs_config\n",
    "\n",
    "sys.path.insert(0, \"/Users/admin/Code/SCS/scs/models/\")\n",
    "import feed_forward\n",
    "import transformer_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2531b645-75f7-47a8-af87-6a25df30b3df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(1415)\n",
    "overwrite = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a06bc432-ddfa-4d3e-a05b-15099c4552c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gen_noise(spectrum, noise_scale, rng):\n",
    "    filt = savgol_filter(spectrum, 10, 1, mode=\"mirror\")\n",
    "    res = spectrum - filt\n",
    "    noise = res * noise_scale\n",
    "    return noise\n",
    "gen_noise = np.vectorize(gen_noise, signature=\"(n),(),()->(n)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a904bce-ee58-43d0-847f-01b3b186f5ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load original dataset\n",
    "\n",
    "file_df_raw = \"/Users/admin/Code/SCS/data/raw/sn_data.parquet\"\n",
    "df_raw = pd.read_parquet(file_df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ebc3c750-23ba-4b2d-8c86-070ff5eeee21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "## Inject Noise\n",
    "\n",
    "data = dp.extract_dataframe(df_raw)\n",
    "index, wvl, flux_columns, metadata_columns, df_fluxes, df_metadata, fluxes = data\n",
    "fluxes_noise = fluxes + gen_noise(fluxes, noise_scale, rng)\n",
    "df_raw[flux_columns] = fluxes_noise\n",
    "\n",
    "## Degrade data\n",
    "\n",
    "R = 100\n",
    "\n",
    "file_df_R = f\"/Users/admin/Code/SCS/data/R{R}/df_R.parquet\"\n",
    "file_df_C = f\"/Users/admin/Code/SCS/data/R{R}/df_C.parquet\"\n",
    "if (not overwrite) and (isfile(file_df_R) and isfile(file_df_C)):\n",
    "    df_R = pd.read_parquet(file_df_R)\n",
    "    df_C = pd.read_parquet(file_df_C)\n",
    "else:\n",
    "    df_C, df_R = dd.degrade_dataframe(R, df_raw)\n",
    "    df_R.to_parquet(file_df_R)\n",
    "    df_C.to_parquet(file_df_C)\n",
    "\n",
    "## Clean data\n",
    "\n",
    "phase_range = (-20, 50)\n",
    "ptp_range = (0.1, 100)\n",
    "wvl_range = (4500, 7000)\n",
    "\n",
    "file_df_RP = f\"/Users/admin/Code/SCS/data/R{R}/df_RP.parquet\"\n",
    "file_df_CP = f\"/Users/admin/Code/SCS/data/R{R}/df_CP.parquet\"\n",
    "if (not overwrite) and (isfile(file_df_RP) and isfile(file_df_CP)):\n",
    "    df_RP = pd.read_parquet(file_df_RP)\n",
    "    df_CP = pd.read_parquet(file_df_CP)\n",
    "else:\n",
    "\n",
    "    df_RP = dp.preproccess_dataframe(df_R, phase_range=phase_range, ptp_range=ptp_range, wvl_range=wvl_range)\n",
    "    df_CP = dp.preproccess_dataframe(df_C, phase_range=phase_range, ptp_range=ptp_range, wvl_range=wvl_range)\n",
    "    df_RP.to_parquet(file_df_RP)\n",
    "    df_CP.to_parquet(file_df_CP)\n",
    "\n",
    "## Train-Test split\n",
    "\n",
    "train_frac = 0.50\n",
    "\n",
    "file_df_RP_trn = f\"/Users/admin/Code/SCS/data/R{R}/df_RP_trn.parquet\"\n",
    "file_df_CP_trn = f\"/Users/admin/Code/SCS/data/R{R}/df_CP_trn.parquet\"\n",
    "file_df_RP_tst = f\"/Users/admin/Code/SCS/data/R{R}/df_RP_tst.parquet\"\n",
    "file_df_CP_tst = f\"/Users/admin/Code/SCS/data/R{R}/df_CP_tst.parquet\"\n",
    "if (not overwrite) and (isfile(file_df_RP_trn) and isfile(file_df_CP_trn) and isfile(file_df_RP_tst) and isfile(file_df_CP_tst)):\n",
    "    df_RP_trn = pd.read_parquet(file_df_RP_trn)\n",
    "    df_CP_trn = pd.read_parquet(file_df_CP_trn)\n",
    "    df_RP_tst = pd.read_parquet(file_df_RP_tst)\n",
    "    df_CP_tst = pd.read_parquet(file_df_CP_tst)\n",
    "else:\n",
    "    df_RP_trn, df_RP_tst = dp.split_data(df_RP, train_frac, rng)\n",
    "    df_CP_trn, df_CP_tst = dp.split_data(df_CP, train_frac, rng)\n",
    "    df_RP_trn.to_parquet(file_df_RP_trn)\n",
    "    df_CP_trn.to_parquet(file_df_CP_trn)\n",
    "    df_RP_tst.to_parquet(file_df_RP_tst)\n",
    "    df_CP_tst.to_parquet(file_df_CP_tst)\n",
    "\n",
    "## Augment training set\n",
    "# noise_scale = 0.25\n",
    "spike_scale = 3\n",
    "max_spikes = 5\n",
    "\n",
    "file_df_RPA_trn = f\"/Users/admin/Code/SCS/data/R{R}/df_RPA_trn.parquet\"\n",
    "file_df_CPA_trn = f\"/Users/admin/Code/SCS/data/R{R}/df_CPA_trn.parquet\"\n",
    "df_RPA_trn = da.augment(df_RP_trn, rng, wvl_range=wvl_range, noise_scale=noise_scale, spike_scale=spike_scale, max_spikes=max_spikes)\n",
    "df_CPA_trn = da.augment(df_CP_trn, rng, wvl_range=wvl_range, noise_scale=noise_scale, spike_scale=spike_scale, max_spikes=max_spikes)\n",
    "df_RPA_trn.to_parquet(file_df_RPA_trn)\n",
    "df_CPA_trn.to_parquet(file_df_CPA_trn)\n",
    "\n",
    "## Ready dataset for ML\n",
    "\n",
    "df_trn = df_RPA_trn\n",
    "df_tst = df_RP_tst\n",
    "Xtrn, Ytrn, num_trn, num_wvl, num_classes = extract(df_trn)\n",
    "Xtst, Ytst, num_tst, num_wvl, num_classes = extract(df_tst)\n",
    "\n",
    "# Machine Learning\n",
    "\n",
    "## Initialize model\n",
    "\n",
    "input_shape = Xtrn.shape[1:]\n",
    "units = [1024, 1024, 1024]\n",
    "model = feed_forward.model(input_shape, num_classes, units, activation=\"relu\", dropout=0.1)\n",
    "model.summary()\n",
    "\n",
    "## Metrics, loss, and optimizer\n",
    "\n",
    "lr0 = 1e-5\n",
    "\n",
    "loss = CategoricalCrossentropy()\n",
    "acc = CategoricalAccuracy(name=\"ca\")\n",
    "f1 = F1Score(num_classes=num_classes, average=\"macro\", name=\"f1\")\n",
    "opt = Nadam(learning_rate=lr0)\n",
    "model.compile(loss=loss, optimizer=opt, metrics=[acc, f1])\n",
    "\n",
    "## Callbacks\n",
    "\n",
    "early = callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0,\n",
    "    patience=10,\n",
    "    verbose=2,\n",
    "    mode=\"min\",\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "file_log = f\"/Users/admin/Code/SCS/data/R{R}/history.log\"\n",
    "logger = callbacks.CSVLogger(file_log, append=False)\n",
    "\n",
    "cbs = [early, logger]\n",
    "\n",
    "## Fit model to training set\n",
    "\n",
    "epochs = 10_000\n",
    "batch_size = 32\n",
    "verbose = 2\n",
    "\n",
    "history = model.fit(\n",
    "    Xtrn,\n",
    "    Ytrn,\n",
    "    validation_data=(Xtst, Ytst),\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    verbose=verbose,\n",
    "    callbacks=cbs,\n",
    ")\n",
    "\n",
    "## Predict on testing set\n",
    "\n",
    "loss_trn, ca_trn, f1_trn = model.evaluate(x=Xtrn, y=Ytrn, verbose=0)\n",
    "loss_tst, ca_tst, f1_tst = model.evaluate(x=Xtst, y=Ytst, verbose=0)\n",
    "\n",
    "print(f\"{f1_tst:.4f}\")\n",
    "print(f\"{f1_trn:.4f}\")\n",
    "print(f\"{ca_tst:.4f}\")\n",
    "print(f\"{ca_trn:.4f}\")\n",
    "print(f\"{loss_tst:.4f}\")\n",
    "print(f\"{loss_tst:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a040e949-a552-42a0-a2fe-9acd8dc05fd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Analysis\n",
    "\n",
    "log = pd.read_csv(file_log)\n",
    "\n",
    "## Loss curves\n",
    "\n",
    "fig = dplt.plot_loss(log, scale=6)\n",
    "fig.show()\n",
    "\n",
    "## Confusion Matrix\n",
    "\n",
    "Ptrn = model.predict(Xtrn)\n",
    "Ptst = model.predict(Xtst)\n",
    "\n",
    "Ptrn_flat = np.argmax(Ptrn, axis=1)\n",
    "Ptst_flat = np.argmax(Ptst, axis=1)\n",
    "\n",
    "Ytrn_flat = np.argmax(Ytrn, axis=1)\n",
    "Ytst_flat = np.argmax(Ytst, axis=1)\n",
    "\n",
    "SNtypes_int = np.unique(Ytrn_flat)\n",
    "SNtypes_str = [scs_config.SN_Stypes_int_to_str[sn] for sn in SNtypes_int]\n",
    "\n",
    "CMtrn = confusion_matrix(Ytrn_flat, Ptrn_flat)\n",
    "CMtst = confusion_matrix(Ytst_flat, Ptst_flat)\n",
    "\n",
    "dplt.plot_cm(CMtst, SNtypes_str, R, normalize=True)\n",
    "# dplt.plot_cm(CMtrn, SNtypes_str, R, normalize=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
